{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_to_Python.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcEIbe1rvuCI"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6WBT2n1Uv5an",
        "outputId": "5f102746-71b5-4c1c-d4d8-c0ffac07fa5d"
      },
      "source": [
        "data = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1fc939d7-c0b5-4ac7-b544-41a30cd8e342\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1fc939d7-c0b5-4ac7-b544-41a30cd8e342\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving eng_python_data.txt to eng_python_data.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhsckoFpwEpe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy.data import Field, BucketIterator,TabularDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import keyword"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gDjuM85whDg"
      },
      "source": [
        "import torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b48a-HUfwjML"
      },
      "source": [
        "SEED = 3333\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c76fgc_wlOD"
      },
      "source": [
        "#out dataframe\n",
        "out_df = pd.DataFrame(columns = ['src', 'python'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nAKU3HSwoFo"
      },
      "source": [
        "input_file = 'eng_python_data.txt'\n",
        "output_file = os.path.join('analysis_shortv3.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2zyA-G5w7Pq",
        "outputId": "821516fd-5d46-4ae9-c5d8-5b6da88aefc9"
      },
      "source": [
        "# first print all lines starting with # with count\n",
        "with open(output_file,'w') as out_file:\n",
        "    eng_buf = ''\n",
        "    py_buf = ''\n",
        "    samples = 0\n",
        "    with open(input_file) as in_file:\n",
        "        for idx,line in enumerate(in_file):\n",
        "            if line.startswith('#') and len(line) > 30:\n",
        "                samples = samples + 1\n",
        "                out_df.loc[len(out_df)] = [eng_buf,py_buf]\n",
        "                py_buf = ''\n",
        "                eng_buf = line\n",
        "\n",
        "            else :\n",
        "                py_buf = py_buf + line\n",
        "\n",
        "print(f\" Count of # :{idx}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Count of # :42424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDxP_1L9yDom"
      },
      "source": [
        "# Data cleaning\n",
        "\n",
        "# Replace tabs with 4 spaces and trim leading and trailing spaces\n",
        "\n",
        "out_df['python']= out_df['python'].str.replace('\\t', '    ')\n",
        "out_df['python']= out_df['python'].str.strip()\n",
        "\n",
        "# clean spaces \n",
        "# 3->4\n",
        "# 7->8\n",
        "# 11->12\n",
        "\n",
        "reg3s_pat = re.compile(r'(:?\\n)[\\s]{3}([\\w])')\n",
        "reg7s_pat = re.compile(r'(:?\\n)[\\s]{7}([\\w])')\n",
        "reg11s_pat = re.compile(r'(:?\\n)[\\s]{11}([\\w])')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oTR-UIAxrDe"
      },
      "source": [
        "def regex_clean(val):\n",
        "\n",
        "    clean_py = reg3s_pat.sub(r'\\1    \\2', val)\n",
        "    clean_py = reg7s_pat.sub(r'\\1        \\2', clean_py)\n",
        "    clean_py = reg11s_pat.sub(r'\\1            \\2', clean_py)\n",
        "    \n",
        "    return clean_py\n",
        "\n",
        "out_df['trg'] = out_df['python'].apply(regex_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO3eEmfgyBCF"
      },
      "source": [
        "### Data Augmentation ( needed as model will overfit)\n",
        "\n",
        "# Patterns to match function and variable names\n",
        "func_pat = re.compile('def (?P<func_name>[\\w]+?)\\(')\n",
        "var_pat = re.compile(r'\\n\\s*(?P<var_name>[\\w]+?)\\s*=')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSQU35PhyqaZ"
      },
      "source": [
        "# Create new dataset by regex matching function \n",
        "# and variable names and giving generic names\n",
        "\n",
        "final_df = pd.DataFrame(columns = ['src','trg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly_CPo0kytg4"
      },
      "source": [
        "for row_idx,row in out_df.iterrows():\n",
        "  final_df.loc[len(final_df)] = [row.src,row.trg]\n",
        "  var_list = []\n",
        "  func_list = []\n",
        "  func_list = list(set(func_pat.findall(row.trg)))\n",
        "  var_list = list(set(var_pat.findall(row.trg)))\n",
        "\n",
        "  if var_list:\n",
        "    for var_idx,var in enumerate(var_list):\n",
        "      varname = \"var_\"+ str(var_idx)\n",
        "      final_df.loc[len(final_df)] = [row.src,row.trg.replace(var,varname)]\n",
        "  if func_list:\n",
        "    for func_idx,func in enumerate(func_list):\n",
        "      funcname = \"func_\"+ str(func_idx)\n",
        "      final_df.loc[len(final_df)] = [row.src,row.trg.replace(func,funcname)]\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgIWZYFrzUJO",
        "outputId": "7090c87a-ec9e-48e2-d003-ebeb3765fa7d"
      },
      "source": [
        "final_df['len'] = final_df['trg'].str.len()\n",
        "fout_df = final_df[final_df['len'] < 500][['src','trg']]\n",
        "print(len(fout_df)/len(final_df))\n",
        "fout_df.to_csv('p_data.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-03 09:38:17.510 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8974421240084183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA2LdxhgzcPt",
        "outputId": "a0acaf0e-e51f-47dd-f1e3-dbaadb26bf1a"
      },
      "source": [
        "print(f\"Data Samples after augmentation : {len(final_df)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Samples after augmentation : 12354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC4iF5AUzeoL"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jLT90HQzgNK"
      },
      "source": [
        "# Tokenization\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZheXhbIzmZQ"
      },
      "source": [
        "kw_dict = {}\n",
        "for kw in keyword.kwlist:\n",
        "  kw_dict[kw]= [{\"ORTH\":kw}]\n",
        "\n",
        "# learn 4, 8 12 spaces\n",
        "special_tabs = ['\\\\n    ','\\\\n        ','\\\\n            ']\n",
        "for tab in special_tabs:\n",
        "    kw_dict[tab] = [{\"ORTH\":tab}]\n",
        "\n",
        "special_cases = kw_dict\n",
        "infix_re = re.compile(r'''(==|>=|<=|!=|\\,|\\?|\\:|\\;|.\n",
        "                          |\\‘|\\’|\\`|\\“|\\”|\\\"|\\'|~|\\(|\\)|\\[|\\])''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8il3Q_EqzzBF"
      },
      "source": [
        "def python_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, \n",
        "                    infix_finditer=infix_re.finditer)\n",
        "\n",
        "\n",
        "py_custom = python_tokenizer(spacy_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w84eOZ3Cz82f"
      },
      "source": [
        "#Modified the py thokenizer to factor spaces\n",
        "\n",
        "def tokenize_py(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    token_texts = []\n",
        "    for token in py_custom(text):\n",
        "       token_texts.append(token.text)\n",
        "       if token.whitespace_:  # filter out empty strings\n",
        "           token_texts.append(token.whitespace_)\n",
        "    return token_texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zssDUrdXz-ud"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = tokenize_py, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "fields = {'src' : ('src', SRC),\n",
        "          'trg' : ('trg', TRG)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22CXqg7WZeVc"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Data/SRC.pkl\",\"wb\") as f:\n",
        "  pickle.dump(SRC,f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Data/TRG.pkl\",\"wb\") as f:\n",
        "  pickle.dump(TRG,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsuYwxLh0BbP"
      },
      "source": [
        "e2p_data  = TabularDataset(\n",
        "                            path = 'p_data.csv',\n",
        "                            format = 'csv',\n",
        "                            fields = fields\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzXj7bk0DWU"
      },
      "source": [
        "train_data, valid_data, test_data = e2p_data.split([0.7,.2,.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eFrr9Hd0Ftd"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 1)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9shvbnfvNtqT"
      },
      "source": [
        "import pickle\n",
        "#save the dictionary as pickle file to be used during inference\n",
        "with open(\"/content/drive/MyDrive/Data/src_stio.pkl\",\"wb\") as f:\n",
        "  pickle.dump(SRC.vocab.stoi,f)\n",
        "with open(\"/content/drive/MyDrive/Data/src_itos.pkl\",\"wb\") as f:\n",
        "  pickle.dump(SRC.vocab.itos,f)\n",
        "\n",
        "#save the dictionary as pickle file to be used during inference\n",
        "with open(\"/content/drive/MyDrive/Data/trg_stio.pkl\",\"wb\") as f:\n",
        "  pickle.dump(TRG.vocab.stoi,f)\n",
        "with open(\"/content/drive/MyDrive/Data/trg_itos.pkl\",\"wb\") as f:\n",
        "  pickle.dump(TRG.vocab.itos,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JCvlTmO0Lal",
        "outputId": "d00b5816-2845-40be-bc1b-7d0d5aef2430"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTUTsyim0Rd7"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.src))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6K0FguK0yXj"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 300):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "            \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toQc1whG09Oc"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):       \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        \n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yPoU2o31C6s"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps88bO-31QH5"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRFhM3hK1VJN"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 300):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "                        \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "          \n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "       \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrOaHsBv1eMz"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):      \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                        \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "       \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJmslxdC1oNi"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "             \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "             \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "      \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "          \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "               \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "                      \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "      \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "               \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "              \n",
        "        return output, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC5rTNsX1181"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDSjqxWO14ff",
        "outputId": "40c0742d-7f59-4949-ff1f-52e49e238aef"
      },
      "source": [
        "len(TRG.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8740"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPdGKP0f17Wo"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_rkTrmt19WH",
        "outputId": "202ceb23-0b08-4690-86e0-15be6db5de2a"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 9,134,628 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnHUiZuK2BTa"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPxSz-oZ2DOJ"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf0T1WNJ2Efc"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbcgiAc32Wdr"
      },
      "source": [
        "#modified the loss function\n",
        "# Built a custom function\n",
        "# If keyword or tab :5\n",
        "# If among top 50 most frequent : 4 ( most common happen to be ones that help wtih syntax)\n",
        "# Rest had a weight 1\n",
        "\n",
        "py_toks = ['(',')','{','}','[',']',':',',',';',\n",
        "            '+','-','*','/','|','&','<','>','=','.',\n",
        "            '%','==','!=','<=','>=','~','^','**',\n",
        "            '+=','-=','*=','/=','%=','/=','//']\n",
        "\n",
        "weight_list = []\n",
        "for idx,word in enumerate(TRG.vocab.itos):\n",
        "\n",
        "\n",
        "  #default\n",
        "  weight = 1.0 \n",
        " \n",
        "\n",
        "  # keyword or tab or common tokens\n",
        "  if (keyword.iskeyword(word)) or ('\\n' in word) or (word in py_toks):\n",
        "      weight = 2.0\n",
        "  \n",
        "  weight_list.append(weight)\n",
        "\n",
        "class_weights = torch.FloatTensor(weight_list).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-W942wN2fZg"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCJLTPNG23rc"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEs4EXdG2hcx"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asI8_N_A2jyj",
        "outputId": "4bc9fe94-256c-44ff-ba0e-d9c5b9900500"
      },
      "source": [
        "training_vis = pd.DataFrame(columns=['epoch','train_loss','val_loss'])\n",
        "N_EPOCHS = 15\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), '/content/drive/MyDrive/Data/tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "    training_vis.loc[len(training_vis)] = [epoch+1,train_loss,valid_loss]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 25s\n",
            "\tTrain Loss: 0.331 | Train PPL:   1.392\n",
            "\t Val. Loss: 0.455 |  Val. PPL:   1.576\n",
            "Epoch: 02 | Time: 0m 26s\n",
            "\tTrain Loss: 0.313 | Train PPL:   1.367\n",
            "\t Val. Loss: 0.442 |  Val. PPL:   1.555\n",
            "Epoch: 03 | Time: 0m 25s\n",
            "\tTrain Loss: 0.291 | Train PPL:   1.338\n",
            "\t Val. Loss: 0.434 |  Val. PPL:   1.544\n",
            "Epoch: 04 | Time: 0m 25s\n",
            "\tTrain Loss: 0.280 | Train PPL:   1.323\n",
            "\t Val. Loss: 0.432 |  Val. PPL:   1.540\n",
            "Epoch: 05 | Time: 0m 26s\n",
            "\tTrain Loss: 0.268 | Train PPL:   1.307\n",
            "\t Val. Loss: 0.423 |  Val. PPL:   1.526\n",
            "Epoch: 06 | Time: 0m 26s\n",
            "\tTrain Loss: 0.256 | Train PPL:   1.292\n",
            "\t Val. Loss: 0.414 |  Val. PPL:   1.512\n",
            "Epoch: 07 | Time: 0m 25s\n",
            "\tTrain Loss: 0.246 | Train PPL:   1.279\n",
            "\t Val. Loss: 0.412 |  Val. PPL:   1.510\n",
            "Epoch: 08 | Time: 0m 25s\n",
            "\tTrain Loss: 0.233 | Train PPL:   1.263\n",
            "\t Val. Loss: 0.408 |  Val. PPL:   1.504\n",
            "Epoch: 09 | Time: 0m 25s\n",
            "\tTrain Loss: 0.224 | Train PPL:   1.251\n",
            "\t Val. Loss: 0.412 |  Val. PPL:   1.511\n",
            "Epoch: 10 | Time: 0m 26s\n",
            "\tTrain Loss: 0.213 | Train PPL:   1.238\n",
            "\t Val. Loss: 0.397 |  Val. PPL:   1.488\n",
            "Epoch: 11 | Time: 0m 26s\n",
            "\tTrain Loss: 0.203 | Train PPL:   1.225\n",
            "\t Val. Loss: 0.394 |  Val. PPL:   1.482\n",
            "Epoch: 12 | Time: 0m 26s\n",
            "\tTrain Loss: 0.194 | Train PPL:   1.213\n",
            "\t Val. Loss: 0.393 |  Val. PPL:   1.482\n",
            "Epoch: 13 | Time: 0m 25s\n",
            "\tTrain Loss: 0.185 | Train PPL:   1.203\n",
            "\t Val. Loss: 0.394 |  Val. PPL:   1.483\n",
            "Epoch: 14 | Time: 0m 26s\n",
            "\tTrain Loss: 0.181 | Train PPL:   1.198\n",
            "\t Val. Loss: 0.390 |  Val. PPL:   1.477\n",
            "Epoch: 15 | Time: 0m 25s\n",
            "\tTrain Loss: 0.175 | Train PPL:   1.191\n",
            "\t Val. Loss: 0.393 |  Val. PPL:   1.482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69sEjdBH2rqx"
      },
      "source": [
        "# ax = plt.gca()\n",
        "\n",
        "# training_vis.plot(kind='line',x='epoch',y='train_loss',ax=ax)\n",
        "# training_vis.plot(kind='line',x='epoch',y='val_loss', color='red', ax=ax)\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSCYhmBH6AIE",
        "outputId": "d2e1b7c9-e7d7-48b7-eb03-79cb0ae8602f"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Data/tut6-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 0.395 | Test PPL:   1.485 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtKwz9S-6R5u"
      },
      "source": [
        "# Translating sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb5wVgP56W-D"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 500):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVUMgh9N6Xhz"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
        "    \n",
        "    assert n_rows * n_cols == n_heads\n",
        "    \n",
        "    fig = plt.figure(figsize=(15,25))\n",
        "    \n",
        "    for i in range(n_heads):\n",
        "        \n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
        "        \n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
        "                           rotation=45)\n",
        "        ax.set_yticklabels(['']+translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5dZ8b4W6Zra"
      },
      "source": [
        "# Function to display generated python code\n",
        "\n",
        "def display_py(trans_list):\n",
        "  print('\\n')\n",
        "  final_str = ''\n",
        "  for string in trans_list:\n",
        "    if string != '\\n':\n",
        "      final_str = final_str + string\n",
        "    else:\n",
        "      final_str= final_str + string\n",
        "  return final_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31d5YJEa6bc1",
        "outputId": "b71aed96-a721-4886-8b90-f5f67dcafb2b"
      },
      "source": [
        "example_idx = random.randint(0,len(train_data))\n",
        "\n",
        "src = vars(train_data.examples[example_idx])['src']\n",
        "trg = vars(train_data.examples[example_idx])['trg']\n",
        "\n",
        "print(display_py(trg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "def find_evennumbers(input_list):\n",
            "  var_0 = [var for var in input_list if var % 2 == 0]\n",
            "  return var_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwBfFgKY6dHt",
        "outputId": "ef1df983-bdcf-467c-aa06-fdb7c24621a0"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(display_py(translation[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "def find_evennumbers(input_list):\n",
            "  var_0 = [var for var in input_list if var % 2 == 0]\n",
            "  return var_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKLRUO5w6rhv"
      },
      "source": [
        "# display_attention(src, translation, attention)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8euznNj56wOv",
        "outputId": "5b52cf93-6e21-4a95-a0fd-aca3bb4c278d"
      },
      "source": [
        "example_idx = random.randint(0,len(valid_data))\n",
        "\n",
        "src = vars(valid_data.examples[example_idx])['src']\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\n",
        "\n",
        "print(display_py(trg))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "str1 = \"abc4234afde\"\n",
            "digitcount = 0\n",
            "for i in range(0,len(str1)):\n",
            "  char = str1[i]\n",
            "  if(char.isalpha()):\n",
            "    digitcount += 1\n",
            "print('number of alphanumeric: ',digitcount)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXq0Dy1k67LU",
        "outputId": "6400bb55-9fea-4aa3-f08e-8bd649bafcc3"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(display_py(translation[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "str1 = \"abc4234afde\"\n",
            "digitcount = 0\n",
            "for i in range(0,len(str1)):\n",
            "  char = str1[i]\n",
            "  if(char.isalpha()):\n",
            "    digitcount += 1\n",
            "print('number of alphanumeric: ',digitcount)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG6S05Ee6_eW",
        "outputId": "72ca38e7-8d43-496c-a13e-ace31e99c466"
      },
      "source": [
        "example_idx = random.randint(0,len(test_data))\n",
        "\n",
        "src = vars(test_data.examples[example_idx])['src']\n",
        "trg = vars(test_data.examples[example_idx])['trg']\n",
        "\n",
        "print(display_py(trg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "def func_0(p:float, r:float, t:float, n:float)->float:\n",
            "    return round(p*((1+(r/(n*100)))**(n*t)) - p,2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGLeiYOg7V1T",
        "outputId": "3c1acf33-ee27-49e7-ec9f-d691259e4ee6"
      },
      "source": [
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "print(display_py(translation[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "def get_si(p:float, r:float, t:float)->float:\n",
            "    return (p*r*t)/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RAmUY667aBO"
      },
      "source": [
        "def translate_sentence_vectorized(src_tensor, src_field, trg_field, model, device, max_len=500):\n",
        "    assert isinstance(src_tensor, torch.Tensor)\n",
        "\n",
        "    model.eval()\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "    # enc_src = [batch_sz, src_len, hid_dim]\n",
        "\n",
        "    trg_indexes = [[trg_field.vocab.stoi[trg_field.init_token]] for _ in range(len(src_tensor))]\n",
        "    # Even though some examples might have been completed by producing a <eos> token\n",
        "    # we still need to feed them through the model because other are not yet finished\n",
        "    # and all examples act as a batch. Once every single sentence prediction encounters\n",
        "    # <eos> token, then we can stop predicting.\n",
        "    translations_done = [0] * len(src_tensor)\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        pred_tokens = output.argmax(2)[:,-1]\n",
        "        for i, pred_token_i in enumerate(pred_tokens):\n",
        "            trg_indexes[i].append(pred_token_i)\n",
        "            if pred_token_i == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "                translations_done[i] = 1\n",
        "        if all(translations_done):\n",
        "            break\n",
        "\n",
        "    # Iterate through each predicted example one by one;\n",
        "    # Cut-off the portion including the after the <eos> token\n",
        "    pred_sentences = []\n",
        "    for trg_sentence in trg_indexes:\n",
        "        pred_sentence = []\n",
        "        for i in range(1, len(trg_sentence)):\n",
        "            if trg_sentence[i] == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "                break\n",
        "            pred_sentence.append(trg_field.vocab.itos[trg_sentence[i]])\n",
        "        pred_sentences.append(pred_sentence)\n",
        "\n",
        "    return pred_sentences, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSlOgdE09xTt",
        "outputId": "c019ca8f-fef8-4d86-cc23-901f2f3e05f4"
      },
      "source": [
        "test_sample_idxs = [random.randint(0, len(train_data)) for p in range(0, 10)]\n",
        "for count,example_idx in enumerate(test_sample_idxs):\n",
        "  src = vars(train_data.examples[example_idx])['src']\n",
        "  trg = vars(train_data.examples[example_idx])['trg']\n",
        "  print(50*\"*\" + 'Sample    : ' + str(count + 1) + '  ' + 50*\"*\")\n",
        "  print('\\n')\n",
        "  print(\"*******Gold *******\")\n",
        "  eng = ' '.join(src)\n",
        "  label = display_py(trg)\n",
        "  print(eng)\n",
        "  print(label)\n",
        "  print('\\n')\n",
        "  #print(' '.join(trg))\n",
        "\n",
        "  print(\"*******Predicted *******\")\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "\n",
        "  print(f'predicted trg = {translation}')\n",
        "  print(display_py(translation[:-1]))\n",
        "  print('\\n')\n",
        "  print(100* \"*\")\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************Sample    : 1  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "#   given a python list , remove all occurrence of a given number from the list\n",
            "num1 = 20\n",
            "var_2 = [5, 20, 15, 20, 25, 50, 20]\n",
            "\n",
            "def removevalue(samplelist, val):\n",
            "    return [value for value in samplelist if value != val]\n",
            "reslist = removevalue(var_2, num1)\n",
            "print(reslist)\n",
            "\n",
            "# shuffle a list randomly\n",
            "import random\n",
            "list = [2,5,8,9,12]\n",
            "random.shuffle(list)\n",
            "print (\"printing shuffled list \", list)\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['num1', ' ', '=', ' ', '20', '\\n', 'var_01', ' ', '=', ' ', '[5', ',', ' ', '20', ',', ' ', '15', ',', ' ', '20', ',', ' ', '25', ',', ' ', '50', ',', ' ', '20', ']', '\\n\\n', 'def', ' ', 'removevalue', '(', 'samplelist', ',', ' ', 'val', ')', ':', '\\n    ', 'return', ' ', '[value', ' ', 'for', ' ', 'value', ' ', 'in', ' ', 'samplelist', ' ', 'if', ' ', 'value', ' ', '!=', ' ', 'val', ']', '\\n', 'reslist', ' ', '=', ' ', 'removevalue', '(', 'var_01', ',', ' ', 'num1', ')', '\\n', 'print', '(', 'reslist', ')', '\\n\\n', '#', ' ', 'shuffle', ' ', 'a', ' ', 'var_0', ' ', 'randomly', '\\n', 'import', ' ', 'random', '\\n', 'var_0', ' ', '=', ' ', '[2', ',', '5', ',', '8', ',', '9', ',', '12', ']', '\\n', 'random.shuffle', '(', 'var_0', ')', '\\n', 'print', ' ', '(', '\"', 'printing', ' ', 'shuffled', ' ', 'var_0', ' ', '\"', ',', ' ', 'var_0', ')', '<eos>']\n",
            "\n",
            "\n",
            "num1 = 20\n",
            "var_01 = [5, 20, 15, 20, 25, 50, 20]\n",
            "\n",
            "def removevalue(samplelist, val):\n",
            "    return [value for value in samplelist if value != val]\n",
            "reslist = removevalue(var_01, num1)\n",
            "print(reslist)\n",
            "\n",
            "# shuffle a var_0 randomly\n",
            "import random\n",
            "var_0 = [2,5,8,9,12]\n",
            "random.shuffle(var_0)\n",
            "print (\"printing shuffled var_0 \", var_0)\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 2  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python program to find and print the longest word in a sentence\n",
            "string = \"python java c c++ javascript pascal php\"\n",
            "\n",
            "print(string)\n",
            "\n",
            "var_0 = string.split()\n",
            "\n",
            "id_longest = 0\n",
            "\n",
            "for i in range(1, len(var_0)):\n",
            "    if len(var_0[id_longest]) < len(var_0[i]):\n",
            "        id_longest = i\n",
            "\n",
            "print(var_0[id_longest])\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['sentence', ' ', '=', ' ', \"'the\", ' ', 'quick', ' ', 'brown', ' ', 'fox', ' ', 'jumps', ' ', 'over', ' ', 'the', ' ', 'lazy', ' ', 'dog', \"'\", '\\n', 'words', ' ', '=', ' ', 'sentence.split', '(', \"'\", ' ', \"'\", ')', '\\n', 'lengths', ' ', '=', ' ', '[str', '(', 'len', '(', 'word', ')', ')', ' ', 'for', ' ', 'word', ' ', 'in', ' ', 'words', ']', '\\n', 'print', '(', \"'\", ' ', \"'.join\", '(', 'lengths', ')', ')', '<eos>']\n",
            "\n",
            "\n",
            "sentence = 'the quick brown fox jumps over the lazy dog'\n",
            "words = sentence.split(' ')\n",
            "lengths = [str(len(word)) for word in words]\n",
            "print(' '.join(lengths))\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 3  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python program to print the sum of digits of a number\n",
            "n = 12345\n",
            "q = 0\n",
            "while(n>0):\n",
            " r=n%10\n",
            " q=q+r\n",
            " n=n//10\n",
            "print(\"sum of digits is: \"+str(q))\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['n', ' ', '=', ' ', '12345', '\\n', 'q', ' ', '=', ' ', '0', '\\n', 'while', '(', 'n>0', ')', ':', '\\n ', 'r=n%10', '\\n ', 'q=q+r', '\\n ', 'n=n//10', '\\n', 'print', '(', '\"', 'sum', ' ', 'of', ' ', 'digits', ' ', 'is', ':', ' ', '\"+str', '(', 'q', ')', ')', '<eos>']\n",
            "\n",
            "\n",
            "n = 12345\n",
            "q = 0\n",
            "while(n>0):\n",
            " r=n%10\n",
            " q=q+r\n",
            " n=n//10\n",
            "print(\"sum of digits is: \"+str(q))\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 4  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a function to get the cumulative sum of a list\n",
            "def cumulative(lists):\n",
            "    var_1 = []\n",
            "    length = len(lists)\n",
            "    var_1 = [sum(lists[0:x:1]) for x in range(0, length+1)]\n",
            "    return var_1[1:]\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['def', ' ', 'cumulative', '(', 'lists', ')', ':', '\\n    ', 'cu_list', ' ', '=', ' ', '[', ']', '\\n    ', 'length', ' ', '=', ' ', 'len', '(', 'lists', ')', '\\n    ', 'cu_list', ' ', '=', ' ', '[sum', '(', 'lists', '[', '0', ':', 'x', ':', '1', ']', ')', ' ', 'for', ' ', 'x', ' ', 'in', ' ', 'range', '(', '0', ',', ' ', 'length+1', ')', ']', '\\n    ', 'return', ' ', 'cu_list', '[', '1', ':', ']', '\\n\\n\\n ', '#', ' ', 'write', ' ', 'a', ' ', 'python', ' ', 'program', ' ', 'to', ' ', 'print', ' ', 'if', ' ', 'a', ' ', 'string', ' ', '\"hello', '\"', ' ', 'is', ' ', 'present', ' ', 'in', ' ', 'the', ' ', 'list', '\\n', 'l', ' ', '=', ' ', '[1', ',', ' ', '2.0', ',', ' ', \"'hello\", \"'\", ',', \"'\", 'have', \"'\", ',', ' ', \"'a\", \"'\", ',', ' ', \"'good\", \"'\", ',', ' ', \"'day\", \"'\", ']', '\\n\\n', 's', ' ', '=', ' ', \"'hello\", \"'\", '\\n\\n', 'if', ' ', 's', ' ', 'in', ' ', 'l', ':', '\\n    ', 'print', '(', 'f', \"'\", '{s}', ' ', 'is', ' ', 'present', ' ', 'in', ' ', 'the', ' ', 'list', \"'\", ')', '\\n', 'else', ':', '\\n    ', 'print', '(', 'f', \"'\", '{s}', ' ', 'is', ' ', 'not', ' ', 'present', ' ', 'in', ' ', 'the', ' ', 'list', \"'\", ')', '<eos>']\n",
            "\n",
            "\n",
            "def cumulative(lists):\n",
            "    cu_list = []\n",
            "    length = len(lists)\n",
            "    cu_list = [sum(lists[0:x:1]) for x in range(0, length+1)]\n",
            "    return cu_list[1:]\n",
            "\n",
            "\n",
            " # write a python program to print if a string \"hello\" is present in the list\n",
            "l = [1, 2.0, 'hello','have', 'a', 'good', 'day']\n",
            "\n",
            "s = 'hello'\n",
            "\n",
            "if s in l:\n",
            "    print(f'{s} is present in the list')\n",
            "else:\n",
            "    print(f'{s} is not present in the list')\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 5  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python program to explain the generator\n",
            "def f11(x):\n",
            "    yield x+1\n",
            "var_0=f11(8)\n",
            "print(next(var_0))\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['def', ' ', 'f11', '(', 'x', ')', ':', '\\n    ', 'yield', ' ', 'x+1', '\\n', 'g=f11', '(', '8', ')', '\\n', 'print', '(', 'next', '(', 'g', ')', ')', '<eos>']\n",
            "\n",
            "\n",
            "def f11(x):\n",
            "    yield x+1\n",
            "g=f11(8)\n",
            "print(next(g))\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 6  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python function to check and print if binary representations of two numbers are anagram\n",
            "from collections import counter\n",
            "\n",
            "def checkanagram(num1,num2):\n",
            "    bin1 = bin(num1)[2:]\n",
            "    bin2 = bin(num2)[2:]\n",
            "\n",
            "    zeros = abs(len(bin1)-len(bin2))\n",
            "    if (len(bin1)>len(bin2)):\n",
            "         bin2 = zeros * '0' + bin2\n",
            "    else:\n",
            "         bin1 = zeros * '0' + bin1\n",
            "\n",
            "    dict1 = counter(bin1)\n",
            "    var_4 = counter(bin2)\n",
            "\n",
            "\n",
            "    if dict1 == var_4:\n",
            "         print('yes')\n",
            "    else:\n",
            "         print('no')\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['from', ' ', 'collections', ' ', 'import', ' ', 'counter', '\\n\\n', 'def', ' ', 'checkanagram', '(', 'num1', ',', 'num2', ')', ':', '\\n    ', 'bin1', ' ', '=', ' ', 'bin', '(', 'num2', ')', '[', '2', ':', ']', '\\n    ', 'bin2', ' ', '=', ' ', 'bin', '(', 'num2', ')', '[', '2', ':', ']', '\\n\\n    ', 'zeros', ' ', '=', ' ', 'abs', '(', 'len', '(', 'bin1', ')', '-len', '(', 'bin2', ')', ')', '\\n    ', 'if', ' ', '(len', '(', 'bin1', ')', '>len', '(', 'bin2', ')', ')', ':', '\\n         ', 'bin2', ' ', '=', ' ', 'zeros', ' ', '*', ' ', \"'0\", \"'\", ' ', '+', ' ', 'bin2', '\\n    ', 'else', ':', '\\n         ', 'bin1', ' ', '=', ' ', 'zeros', ' ', '*', ' ', \"'0\", \"'\", ' ', '+', ' ', 'bin1', '\\n\\n    ', 'dict1', ' ', '=', ' ', 'counter', '(', 'bin1', ')', '\\n    ', 'dict2', ' ', '=', ' ', 'counter', '(', 'bin1', ')', '\\n\\n\\n    ', 'if', ' ', 'bin1', ')', ' ', '<=', ' ', 'counter', '(', 'bin1', ')', ' ', 'counter', '(', 'bin1', ')', ' ', 'counter', '(', 'bin1', ')', '\\n    ', 'dict2', ':', '\\n         ', 'print', '(', \"'\", 'yes', \"'\", ')', '\\n\\n\\n    ', 'if', ' ', '__name__', ' ', '==', ' ', 'counter', ' ', ':', '\\n         ', 'print', '(', \"'\", ')', '<eos>']\n",
            "\n",
            "\n",
            "from collections import counter\n",
            "\n",
            "def checkanagram(num1,num2):\n",
            "    bin1 = bin(num2)[2:]\n",
            "    bin2 = bin(num2)[2:]\n",
            "\n",
            "    zeros = abs(len(bin1)-len(bin2))\n",
            "    if (len(bin1)>len(bin2)):\n",
            "         bin2 = zeros * '0' + bin2\n",
            "    else:\n",
            "         bin1 = zeros * '0' + bin1\n",
            "\n",
            "    dict1 = counter(bin1)\n",
            "    dict2 = counter(bin1)\n",
            "\n",
            "\n",
            "    if bin1) <= counter(bin1) counter(bin1) counter(bin1)\n",
            "    dict2:\n",
            "         print('yes')\n",
            "\n",
            "\n",
            "    if __name__ == counter :\n",
            "         print(')\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 7  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# 77 show all local values while one function is running\n",
            "def show_local():\n",
            "    import math\n",
            "    a = 10\n",
            "    var_1 = 'hello there'\n",
            "    print(locals())\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['def', ' ', 'show_local', '(', ')', ':', '\\n    ', 'import', ' ', 'math', '\\n    ', 'a', ' ', '=', ' ', '10', '\\n    ', 'var_1', ' ', '=', ' ', \"'hello\", ' ', 'there', \"'\", '\\n    ', 'print', '(', 'locals', '(', ')', ')', '<eos>']\n",
            "\n",
            "\n",
            "def show_local():\n",
            "    import math\n",
            "    a = 10\n",
            "    var_1 = 'hello there'\n",
            "    print(locals())\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 8  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# given a two list of equal size create a set such that it shows the element from both lists in the pair\n",
            "firstlist = [2, 3, 4, 5, 6, 7, 8]\n",
            "secondlist = [4, 9, 16, 25, 36, 49, 64]\n",
            "result = zip(firstlist, secondlist)\n",
            "resultset = set(result)\n",
            "print(resultset)\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['firstlist', ' ', '=', ' ', '[2', ',', ' ', '3', ',', ' ', '4', ',', ' ', '5', ',', ' ', '6', ',', ' ', '7', ',', ' ', '8', ']', '\\n', 'secondlist', ' ', '=', ' ', '[4', ',', ' ', '9', ',', ' ', '16', ',', ' ', '25', ',', ' ', '36', ',', ' ', '49', ',', ' ', '64', ']', '\\n', 'var_0', ' ', '=', ' ', 'zip', '(', 'firstlist', ',', ' ', 'secondlist', ')', '\\n', 'var_0set', ' ', '=', ' ', 'set', '(', 'var_0', ')', '\\n', 'print', '(', 'var_0set', ')', '<eos>']\n",
            "\n",
            "\n",
            "firstlist = [2, 3, 4, 5, 6, 7, 8]\n",
            "secondlist = [4, 9, 16, 25, 36, 49, 64]\n",
            "var_0 = zip(firstlist, secondlist)\n",
            "var_0set = set(var_0)\n",
            "print(var_0set)\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 9  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python function that accepts a string and calculate the number of upper case letters and lower case letters\n",
            "def string_test(s):\n",
            "d={\"upper_case\":0, \"lower_case\":0}\n",
            "for c in s:\n",
            "if c.isupper():\n",
            "d[\"upper_case\"]+=1\n",
            "elif c.islower():\n",
            "d[\"lower_case\"]+=1\n",
            "else:\n",
            "pass\n",
            "print (\"original string : \", s)\n",
            "print (\"no. of upper case characters : \", d[\"upper_case\"])\n",
            "print (\"no. of lower case characters : \", d[\"lower_case\"])\n",
            "\n",
            "string_test('the quick brow fox')\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['def', ' ', 'string_test', '(', 's', ')', ':', '\\n', 'd={', '\"', 'upper_case', '\"', ':', '0', ',', ' ', '\"lower_case', '\"', ':', '0}', '\\n', 'for', ' ', 'c', ' ', 'in', ' ', 's', ':', '\\n', 'if', ' ', 'c.isupper', '(', ')', ':', '\\n', 'd', '[', '\"', 'upper_case', '\"', ']', '+=1', '\\n', 'elif', ' ', 'c.islower', '(', ')', ':', '\\n', 'd', '[', '\"', 'lower_case', '\"', ']', '+=1', '\\n', 'else', ':', '\\n', 'pass', '\\n', 'print', ' ', '(', '\"', 'original', ' ', 'string', ' ', ':', ' ', '\"', ',', ' ', 's', ')', '\\n', 'print', ' ', '(', '\"', 'no.', ' ', 'of', ' ', 'upper', ' ', 'case', ' ', 'characters', ' ', ':', ' ', '\"', ',', ' ', 'd', '[', '\"', 'upper_case', '\"', ']', ')', '\\n', 'print', ' ', '(', '\"', 'no.', ' ', 'of', ' ', 'lower', ' ', 'case', ' ', 'characters', ' ', ':', ' ', '\"', ',', ' ', 'd', '[', '\"', 'lower_case', '\"', ']', ')', '\\n\\n', 'string_test', '(', \"'\", 'the', ' ', 'quick', ' ', 'brow', ' ', 'fox', \"'\", ')', '<eos>']\n",
            "\n",
            "\n",
            "def string_test(s):\n",
            "d={\"upper_case\":0, \"lower_case\":0}\n",
            "for c in s:\n",
            "if c.isupper():\n",
            "d[\"upper_case\"]+=1\n",
            "elif c.islower():\n",
            "d[\"lower_case\"]+=1\n",
            "else:\n",
            "pass\n",
            "print (\"original string : \", s)\n",
            "print (\"no. of upper case characters : \", d[\"upper_case\"])\n",
            "print (\"no. of lower case characters : \", d[\"lower_case\"])\n",
            "\n",
            "string_test('the quick brow fox')\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "**************************************************Sample    : 10  **************************************************\n",
            "\n",
            "\n",
            "*******Gold *******\n",
            "\n",
            "\n",
            "# write a python program to combine two dictionary by adding values for common keys\n",
            "dict1 = {'a': 12, 'for': 25, 'c': 9}\n",
            "dict2 = {'geeks': 100, 'geek': 200, 'for': 300}\n",
            "for key in dict2:\n",
            "    if key in dict1:\n",
            "        dict2[key] = dict2[key] + dict1[key]\n",
            "    else:\n",
            "        pass\n",
            "\n",
            "\n",
            "*******Predicted *******\n",
            "predicted trg = ['dict1', ' ', '=', ' ', '{', \"'\", 'a', \"'\", ':', ' ', '12', ',', ' ', \"'for\", \"'\", ':', ' ', '25', ',', ' ', \"'c\", \"'\", ':', ' ', '9}', '\\n', 'var_0', ' ', '=', ' ', '{', \"'\", 'geeks', \"'\", ':', ' ', '100', ',', ' ', \"'geek\", \"'\", ':', ' ', '200', ',', ' ', \"'for\", \"'\", ':', ' ', '300}', '\\n', 'for', ' ', 'key', ' ', 'in', ' ', 'var_0', ':', '\\n    ', 'if', ' ', 'key', ' ', 'in', ' ', 'var_0', ':', '\\n        ', 'var_0', '[', 'key', ']', ' ', '=', ' ', 'var_0', '[', 'key', ']', ' ', '+', ' ', 'dict1', '[', 'key', ']', '\\n    ', 'else', ':', '\\n        ', 'pass', '<eos>']\n",
            "\n",
            "\n",
            "dict1 = {'a': 12, 'for': 25, 'c': 9}\n",
            "var_0 = {'geeks': 100, 'geek': 200, 'for': 300}\n",
            "for key in var_0:\n",
            "    if key in var_0:\n",
            "        var_0[key] = var_0[key] + dict1[key]\n",
            "    else:\n",
            "        pass\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4WxW1KIEKIC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}